---
title: "Stat418 HW3"
author: "Ruifu Jiang"
output: html_document
---

# 1 Input data

The first step is downloading and inputing the dataset to R. The purpose is to find what predictors influence the income over 50k. Then transfered the response variable to "0" if income is less or equal to 50k and "1" if income is greater than 50k. And split data into train, validation and test set with ratio 6:2:2. 
```{r}
col_names <- c("age", "workclass", "fnlwgt", "education", "education-num", "marital-status", "occupation", "relationship", "race", "sex", "capital-gain", "capital-loss", "hours-per-week", "native-country","Y")
adult.data<- read.csv("/Users/Ruifu/Downloads/adult.data.csv", header = FALSE, col.names = col_names)

adult.data$Y<- as.character(adult.data$Y)
adult.data$Y<- ifelse(adult.data$Y ==" >50K",1,0)

set.seed(123)
N <- nrow(adult.data)
idx <- sample(seq(1, 3), size = N, replace = TRUE, prob = c(.6, .2, .2))
adult_train <- adult.data[idx == 1,]
adult_vali<- adult.data[idx == 2,]
adult_test <- adult.data[idx == 3,]
```

# ML analysis with R package

## 1 LR

First is to try the logestic regression with the best lambda 0.000498676.

```{r}
library(glmnet)
X <- Matrix::sparse.model.matrix(Y ~ . - 1, data = adult.data)
X_train <- X[idx == 1,]
X_vali<- X[idx == 2,]
X_test <- X[idx == 3,]

md <- cv.glmnet(X_train, adult_train$Y)
plot(md)
md <- glmnet( X_train, adult_train$Y, family = "binomial", lambda = 0.000498676)
```


```{r}
library(ROCR)
phat <- predict(md, newx = X_test, type = "response")

rocr_pred <- prediction(phat, adult_test$Y)
performance(rocr_pred, "auc")@y.values[[1]]

plot(performance(rocr_pred, "tpr", "fpr"), colorize = T)
```

The AUC is close to 1 which means this model is a good fit.  
As we can see from the plot, when the true positive rate increases, the false positive rate increases as well. The AUC is the area under the curve. As long as the area close to 1, it becomes easier to find a point where the true positive rate is high and the false positive rate is low.


## 2 RF

Then try to build model with Random Forest method. First is to set different number of trees and depth of trees to get different models with train set. And use validation set to choose the best model with the biggest AUC. finally use the test set to test the best model.
```{r}
library(randomForest)
set.seed(123)
RF1<- randomForest(as.factor(Y) ~ ., data = adult_train, ntree = 100, depth = 5)
RF2<- randomForest(as.factor(Y) ~ ., data = adult_train, ntree = 10, depth = 5)
RF3<- randomForest(as.factor(Y) ~ ., data = adult_train, ntree = 100, depth = 10)

RF1phat<- predict(RF1, adult_vali, type = "prob")[,"1"]
RF1rocr_pred <- prediction(RF1phat, adult_vali$Y)
performance(RF1rocr_pred, "auc")@y.values[[1]]

RF2phat<- predict(RF2, adult_vali, type = "prob")[,"1"]
RF2rocr_pred <- prediction(RF2phat, adult_vali$Y)
performance(RF2rocr_pred, "auc")@y.values[[1]]

RF3phat<- predict(RF3, adult_vali, type = "prob")[,"1"]
RF3rocr_pred <- prediction(RF3phat, adult_vali$Y)
performance(RF3rocr_pred, "auc")@y.values[[1]]

RF1
plot(RF1)
```

Actually, we can write a loop for each parameter to try different number and compare each AUC to get the best number. As this cost too much time in my laptop, I choose several numbers instead.  

Then use random forest cross validation to find the best number of columns used in each split which is 7.
```{r}
rfcv(adult_train[ ,-15],as.factor(adult_train$Y))
```
Finally test this model with test set. The AUC of this model is 0.863745
```{r}
RF<- randomForest(as.factor(Y) ~ ., data = adult_train, ntree = 100, depth = 5, mtry = 7)
RFphat <- predict(RF, adult_test, type = "prob")[,"1"]
RFrocr_pred <- prediction(RFphat, adult_test$Y)
performance(RFrocr_pred, "auc")@y.values[[1]]
```


## 3 GBM

The third method is Generalized Boosted Regression Modeling. Similar to random forest, tune the number of trees, the depth of trees, and the learning rate(shrinkage) wiht several numbers, then use cross validation to find the best number of trees which is . Finally use test set to check the AUC which is 0.9190633. For gbm package, it's hard to do early stopping, which means it's possible to get overfitted if we set a great number of trees and the AUC is almost 1. More details about early stopping will be discussed in next part h2o.
```{r}
library(gbm)
set.seed(123)

md <- gbm(Y ~ ., data = adult_train, distribution = "bernoulli",
          n.trees = 100, interaction.depth = 10, shrinkage = 0.01)

yhat <- predict(md, adult_test, n.trees = 100) 
table(ifelse(yhat>0,1,0), adult_test$Y)

md <- gbm(Y ~ ., data = adult_train, distribution = "bernoulli",
          n.trees = 100, interaction.depth = 10, shrinkage = 0.01, cv.folds = 5)
gbm.perf(md, plot.it = TRUE)

md <- gbm(Y ~ ., data = adult_train, distribution = "bernoulli",
          n.trees = 100, interaction.depth = 10, shrinkage = 0.3, cv.folds = 5)
gbm.perf(md, plot.it = TRUE)


yhat <- predict(md, adult_test, n.trees = gbm.perf(md, plot.it = FALSE))

GBM_pred <- prediction(yhat, adult_test$Y)
performance(GBM_pred, "auc")@y.values[[1]]
```


# ML analysis with h2o

The porcedure of analyzing with h2o is pretty similar to the one with R package. Key code is show below.

## 1 LR
```{r}
library(h2o)
h2o.init(nthreads=-1)
dx <- h2o.importFile("/Users/Ruifu/Downloads/adult.data.csv")

dx_split <- h2o.splitFrame(dx, ratios = 0.6, seed = 123)
dx_train <- dx_split[[1]]
dx_test <- dx_split[[2]]
Xnames <- names(dx_train)[which(names(dx_train)!="C15")]

md <- h2o.glm(x = Xnames, y = "C15", training_frame = dx_train, 
              family = "binomial", alpha = 1, lambda = 0)

h2o.auc(h2o.performance(md, dx_test))
md
```



## 2 RF
```{r}
md <- h2o.randomForest(x = Xnames, y = "C15", training_frame = dx_train, ntrees = 500)
h2o.auc(h2o.performance(md, dx_test))
md
```


## 3 GBM
```{r}
md <- h2o.gbm(x = Xnames, y = "C15", training_frame = dx_train, distribution = "bernoulli", 
                ntrees = 100, max_depth = 10, learn_rate = 0.01, 
                nbins = 100, seed = 123)  
md

md <- h2o.gbm(x = Xnames, y = "C15", training_frame = dx_train, distribution = "bernoulli", 
                ntrees = 10, max_depth = 10, learn_rate = 0.01, 
                nbins = 100, seed = 123)  
md

md <- h2o.gbm(x = Xnames, y = "C15", training_frame = dx_train, distribution = "bernoulli", 
                ntrees = 100, max_depth = 20, learn_rate = 0.3, 
                nbins = 100, seed = 123) 
md

h2o.auc(h2o.performance(md, dx_test))
```

In h2o, we have several way for early stopping.   
First, stop model building if misclassification improves (goes down) by less than one percent between individual scoring events. (stopping_rounds=1, stopping_tolerance=0.01, stopping_metric="misclassification")  
second, stop model building if the logloss on the validation set does not improve at all for 3 consecutive scoring events. (validation_frame, stopping_rounds=3, stopping_tolerance=0, stopping metric="logloss")  
Third, stop model building if the simple moving average (window length 5) of the AUC improves (goes up) by less than 0.1 percent for 5 consecutive scoring events. (stopping_rounds=5, stopping_tolerance=0.001, stopping_metric="AUC")  
Fourth, stop model training after a given amount of seconds. (max runtime secs > 0)







